{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import eznf\n",
    "from eznf import datasets\n",
    "from eznf.autograd import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eznf.datasets.MNIST.MNIST"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(1,3)\n",
    "datasets.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, *args, device=None, requires_grad=False, grad_fn=None, is_leaf=True):\n",
    "        if(len(args) == 0):\n",
    "            self.item = np.random.randn(1)\n",
    "        elif(isinstance(args[0], list) or isinstance(args[0], np.ndarray) or isinstance(args[0], float)):\n",
    "            self.item = np.array(args[0], float).round(4)\n",
    "        elif(isinstance(args[0], Tensor)):\n",
    "            self.item = args[0].item\n",
    "        else:\n",
    "            self.item = np.random.randn(*args)\n",
    "\n",
    "        self.requires_grad = requires_grad\n",
    "        self.grad_fn = grad_fn\n",
    "        self.is_leaf = is_leaf\n",
    "        self.device = device\n",
    "        self.grad = None\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return Tensor(np.array(self.item.shape))\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return Tensor(np.array(self.item.T))\n",
    "\n",
    "    def size(self):\n",
    "        return self.item.size\n",
    "\n",
    "    def dim(self):\n",
    "        return len(self.item.shape)\n",
    "\n",
    "    def mean(self, axis=None):\n",
    "        return Tensor(self.item.mean(axis=axis).round(4))\n",
    "\n",
    "    def var(self, axis=None):\n",
    "        if(axis != None):\n",
    "            n = self.item.shape[axis]\n",
    "        else:\n",
    "            n = self.item.size\n",
    "        return Tensor(np.array(self.item.var(axis=axis)*n/(n-1)).round(4))\n",
    "\n",
    "    def std(self, axis=None):\n",
    "        if(axis != None):\n",
    "            n = self.item.shape[axis]\n",
    "        else:\n",
    "            n = self.item.size\n",
    "        return self.var().sqrt()\n",
    "\n",
    "    def abs(self):\n",
    "        return Tensor(np.abs(self.item))\n",
    "\n",
    "    def argmin(self, axis=None):\n",
    "        tensor = Tensor()\n",
    "        tensor.item = self.item.argmin(axis=axis)\n",
    "        return tensor\n",
    "    \n",
    "    def argmax(self, axis=None):\n",
    "        tensor = Tensor()\n",
    "        tensor.item = self.item.argmax(axis=axis)\n",
    "        return tensor\n",
    "\n",
    "    def view(self, *args):\n",
    "        return Tensor(self.item.reshape(*args))\n",
    "\n",
    "    def sqrt(self):\n",
    "        return Tensor(np.sqrt(self.item))\n",
    "\n",
    "    def tolist(self):\n",
    "        return self.item.tolist()\n",
    "\n",
    "    def numpy(self):\n",
    "        return self.item\n",
    "\n",
    "    def sin(self):\n",
    "        return Tensor(np.sin(self.item))\n",
    "\n",
    "    def cos(self):\n",
    "        return Tensor(np.cos(self.item))\n",
    "\n",
    "    def tan(self):\n",
    "        return Tensor(np.tan(self.item))\n",
    "\n",
    "    def tanh(self):\n",
    "        return Tensor(np.tanh(self.item))\n",
    "\n",
    "    def exp(self):\n",
    "        return Tensor(np.exp(self.item))\n",
    "\n",
    "    def mm(self, mat2):\n",
    "        if(not isinstance(mat2, Tensor)):\n",
    "            raise TypeError(\"mat2 must be a Tensor\")\n",
    "        return Tensor(np.matmul(self.item, mat2))\n",
    "\n",
    "    def copy(self):\n",
    "        return Tensor(self.item.copy())\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'tensor(\\n{}\\n)'.format(self.item)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'tensor(\\n{}\\n)'.format(self.item)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if(not isinstance(other, Tensor)):\n",
    "            other = Tensor([other])\n",
    "        requires_grad = self.requires_grad or other.requires_grad\n",
    "        if(requires_grad):\n",
    "            grad_fn = function.AddBackward(self, other, requires_grad=requires_grad)\n",
    "        else:\n",
    "            grad_fn = None\n",
    "        return Tensor(self.item + other.item, requires_grad=requires_grad, grad_fn=grad_fn, is_leaf=False)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if(not isinstance(other, Tensor)):\n",
    "            other = Tensor([other])\n",
    "        requires_grad = self.requires_grad or other.requires_grad\n",
    "        if(requires_grad):\n",
    "            grad_fn = function.MulBackward(self, other, requires_grad=requires_grad)\n",
    "        else:\n",
    "            grad_fn = None\n",
    "        return Tensor(self.item * other.item, requires_grad=requires_grad, grad_fn=grad_fn, is_leaf=False)\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "\n",
    "    # 重载 @ 运算符\n",
    "    def __matmul__(self, other):\n",
    "        if(not isinstance(other, Tensor)):\n",
    "            other = Tensor([other])\n",
    "        requires_grad = self.requires_grad or other.requires_grad\n",
    "        if(requires_grad):\n",
    "            grad_fn = function.DotBackward(self, other, requires_grad=requires_grad)\n",
    "        else:\n",
    "            grad_fn = None\n",
    "        \n",
    "        try:\n",
    "            res = self.item @ other.item\n",
    "        except:\n",
    "            raise ValueError('mat1 and mat2 shapes cannot be multiplied ({} and {})'.format(self.item.shape, other.item.shape))\n",
    "\n",
    "        return Tensor(res, requires_grad=requires_grad, grad_fn=grad_fn, is_leaf=False)\n",
    "\n",
    "    def __rmatmul__(self, other):\n",
    "        return self.__matmul__(other)\n",
    "\n",
    "    def backward(self, output=None):\n",
    "        if(not output):\n",
    "            output = Tensor([1])\n",
    "        if(self.size() != output.size()):\n",
    "            raise RuntimeError('grad can be implicitly created only for scalar outputs')\n",
    "        if(self.grad_fn):\n",
    "            self.grad_fn.backward(output)\n",
    "        else:\n",
    "            if(self.grad):\n",
    "                self.grad += output\n",
    "            else:\n",
    "                self.grad = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(\n",
       "[[ 2. -4.  6.]\n",
       " [-2.  4.  6.]\n",
       " [ 2.  4. -6.]\n",
       " [ 8. 10. 12.]]\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Tensor([[1,-2,3],[-1,2,3],[1,2,-3],[4,5,6]])\n",
    "a = Tensor([[1,-2,3],[-1,2,3],[1,2,-3],[4,5,6]])\n",
    "Tensor(a.item + b.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3., 3., 3.], requires_grad=True)\n",
    "b = torch.tensor([[2., 2., 2.]], requires_grad=False)\n",
    "c = a @ a\n",
    "c.backward()\n",
    "# c\n",
    "# a.grad\n",
    "# c.backward()\n",
    "# a.grad\n",
    "# d = c + a\n",
    "# d.grad_fn.next_functions\n",
    "# a.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied ((1,) and (3,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\QQDownload\\神经网络课程设计\\代码\\eznf_test.ipynb Cell 6\u001b[0m in \u001b[0;36mTensor.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem \u001b[39m@\u001b[39;49m other\u001b[39m.\u001b[39;49mitem\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\QQDownload\\神经网络课程设计\\代码\\eznf_test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m c \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m a\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# c.backward(eznf.Tensor([1, 1, 1]))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# a.grad\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m c\u001b[39m.\u001b[39;49mbackward()\n",
      "\u001b[1;32me:\\QQDownload\\神经网络课程设计\\代码\\eznf_test.ipynb Cell 6\u001b[0m in \u001b[0;36mTensor.backward\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_fn):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrad_fn\u001b[39m.\u001b[39;49mbackward(output)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad):\n",
      "File \u001b[1;32me:\\QQDownload\\神经网络课程设计\\代码\\eznf\\autograd\\function.py:50\u001b[0m, in \u001b[0;36mDotBackward.backward\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m, output \u001b[39m=\u001b[39m Tensor([\u001b[39m1\u001b[39m])):\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39mrequires_grad):\n\u001b[1;32m---> 50\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39mbackward(output \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\u001b[39m.\u001b[39mrequires_grad):\n\u001b[0;32m     53\u001b[0m         \u001b[39mif\u001b[39;00m(\u001b[39mnot\u001b[39;00m output):\n",
      "\u001b[1;32me:\\QQDownload\\神经网络课程设计\\代码\\eznf_test.ipynb Cell 6\u001b[0m in \u001b[0;36mTensor.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem \u001b[39m@\u001b[39m other\u001b[39m.\u001b[39mitem\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mmat1 and mat2 shapes cannot be multiplied (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem\u001b[39m.\u001b[39mshape, other\u001b[39m.\u001b[39mitem\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/QQDownload/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%A0%81/eznf_test.ipynb#W5sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Tensor(res, requires_grad\u001b[39m=\u001b[39mrequires_grad, grad_fn\u001b[39m=\u001b[39mgrad_fn, is_leaf\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: mat1 and mat2 shapes cannot be multiplied ((1,) and (3,))"
     ]
    }
   ],
   "source": [
    "a = Tensor([3,3,3], requires_grad=True)\n",
    "c = a @ a\n",
    "# c.backward(eznf.Tensor([1, 1, 1]))\n",
    "# a.grad\n",
    "c.backward()\n",
    "# isinstance(Tensor([2]), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = [1, 2, None]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 26 * 36 * 55 * 5 * 5 * 200\n",
    "q2 = 30 * 40 * 20 * 1 * 1 * 200 + 1 * 1 * 55 * 30 * 40 * 50\n",
    "print(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(device='cuda')\n",
    "import cupy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beatsleo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ea64f9ee948d927ad35fd9dd41586a042d593dc7bf73dbea6b47fb27e81f20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
