{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cupy as cpy\n",
    "from tqdm import tqdm\n",
    "import eznf\n",
    "from eznf import Tensor\n",
    "from eznf import datasets\n",
    "from eznf import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(eznf.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.networks = [\n",
    "            # eznf.nn.Cov2d(1, 3, 3),\n",
    "            # eznf.nn.MaxPooling(2),\n",
    "            # eznf.nn.Flatten(),\n",
    "            eznf.nn.Linear(784, 256),\n",
    "            eznf.nn.ReLU(),\n",
    "            eznf.nn.Linear(256, 10)\n",
    "        ]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in self.networks:\n",
    "            x = i(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('./', False)\n",
    "data = dataset.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_train = np.vstack([i.flatten() for i in X_train.item])\n",
    "X_test = np.vstack([i.flatten() for i in X_test.item])\n",
    "\n",
    "Y_train = eznf.one_hot(Tensor(Y_train), 10)\n",
    "X_train = eznf.Tensor(X_train, requires_grad=False)\n",
    "Y_test = eznf.one_hot(Tensor(Y_test), 10)\n",
    "# X_train = X_train[:,None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_grad(m):\n",
    "    for w in m.parameters():\n",
    "        w.grad = None\n",
    "\n",
    "def SGD(m: eznf.nn.Module, alpha):\n",
    "    # 梯度下降\n",
    "    for w in m.parameters():\n",
    "        w.item = w.item - alpha*w.grad.item\n",
    "\n",
    "def accuracy(m, x: eznf.Tensor, y: eznf.Tensor):\n",
    "    pre = m(x).argmax(axis=0)\n",
    "    return ((y.item.argmax(axis=0) == pre.item).sum() / x.shape[1]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:06<00:00,  1.21s/it, acc=0.16, loss=2.32]\n"
     ]
    }
   ],
   "source": [
    "epoches = 5\n",
    "batch_size = 1024\n",
    "steps = len(X_train) // batch_size\n",
    "\n",
    "m = test()\n",
    "loss = eznf.nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(alpha=0.01, model=m)\n",
    "\n",
    "ls = []\n",
    "acc = []\n",
    "\n",
    "with tqdm(total=epoches) as t:\n",
    "    for i in range(epoches):\n",
    "        for j in range(steps):\n",
    "            x = X_train[j*batch_size : (j+1)*batch_size]\n",
    "            y = Y_train[j*batch_size : (j+1)*batch_size]\n",
    "            out = m(x.T)\n",
    "            l = loss(out, y.T) / batch_size\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            ls.append(l.item)\n",
    "            acc.append(accuracy(m, x.T, y.T))\n",
    "        \n",
    "        t.set_description('Epoch {}'.format(i), refresh=False)\n",
    "        t.set_postfix(loss=l.item[0], acc=acc[-1], refresh=False)\n",
    "        t.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10000)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:  2.1707780361175537\n",
      "GPU:  0.005109548568725586\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "a = eznf.ones(1000, 1000)\n",
    "t1 = time()\n",
    "for i in range(100):\n",
    "    b = a @ a\n",
    "print('CPU: ', time() - t1)\n",
    "\n",
    "a.to('gpu')\n",
    "t1 = time()\n",
    "for i in range(100):\n",
    "    b = a @ a\n",
    "print('GPU: ', time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "165072c52a778f8e52483bfeb4aebe819e51e7f8d8bf07bb4ebb429d6c4302cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
